{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    # Automatic Jupyter Notebook for OpenML dataset 152: Hyperplane_10_1E-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import openml as oml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import dummy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "\n",
    "plt.rcParams['figure.dpi']= 120\n",
    "plt.rcParams['xtick.labelsize'] = 8\n",
    "plt.rcParams['ytick.labelsize'] = 8 \n",
    "\n",
    "from preamble import *\n",
    "from sklearn import preprocessing\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The percentage of unique values for the default target attribute in this data set is 0.0.\n",
    "Because this is lower or equal than 5% of the dataset we assume that this is a **classification** problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complexity threshold to determine if an algorithm will be run.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp = 50000000000000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate baseline accuracy for classification problems using scikit-learn DummyClassifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline(data):\n",
    "    strategies = ['stratified','most_frequent','prior','uniform']\n",
    "    baseDict = {}\n",
    "    X, y, features = data.get_data(target=data.default_target_attribute, return_attribute_names=True); \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "    for strat in strategies:\n",
    "        clf = dummy.DummyClassifier(strategy=strat,random_state=0)\n",
    "        clf.fit(X_train, y_train)\n",
    "        baseDict[strat] = clf.score(X_test, y_test)\n",
    "    return baseDict  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generates a plot of the classification baseline accuracy of the various baseline strategies using scikit-learn DummyClassifier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_baseline(scores):\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    from matplotlib.ticker import MaxNLocator\n",
    "    from collections import namedtuple\n",
    "\n",
    "    strats = scores\n",
    "    maxBaseline = strats[max(strats, key=strats.get)]\n",
    "    \n",
    "    n_groups = len(strats)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    index = np.arange(n_groups)\n",
    "    bar_width = 0.1\n",
    "\n",
    "    opacity = 0.4\n",
    "    error_config = {'ecolor': '0.3'}\n",
    "\n",
    "    plt.bar(range(len(strats)), strats.values(), align='center')\n",
    "    plt.xticks(range(len(strats)), list(strats.keys()))\n",
    "    plt.yticks(np.arange(0, 1.1, step=0.2))\n",
    "    plt.yticks(list(plt.yticks()[0]) + [maxBaseline])\n",
    "\n",
    "    ax.set_ylim(ymin=0)\n",
    "    ax.set_ylim(ymax=1)\n",
    "    ax.set_xlabel('Baseline Strategy')\n",
    "    ax.set_ylabel('Accuracy')\n",
    "    ax.set_title('Baseline Performance Predicting Feature: ' + data.default_target_attribute)\n",
    "    plt.axhline(y=maxBaseline, color='r', linestyle='--', label=maxBaseline)\n",
    "    plt.gca().get_yticklabels()[6].set_color('red')\n",
    "    fig.tight_layout()\n",
    "    plt.show() \n",
    "    return maxBaseline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generates a plot of the accuracy of the machinelearning algorithms against the baseline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_alg(scores, maxBaseline):\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    from matplotlib.ticker import MaxNLocator\n",
    "    from collections import namedtuple\n",
    "\n",
    "    strats = scores\n",
    "    \n",
    "    n_groups = len(strats)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    index = np.arange(n_groups)\n",
    "    bar_width = 0.1\n",
    "\n",
    "    opacity = 0.4\n",
    "    error_config = {'ecolor': '0.3'}\n",
    "\n",
    "    barlist =plt.bar(range(len(strats)), strats.values(), align='center')\n",
    "    plt.xticks(range(len(strats)), list(strats.keys()))\n",
    "    plt.yticks(np.arange(0, 1.1, step=0.2))\n",
    "    plt.yticks(list(plt.yticks()[0]) + [maxBaseline])\n",
    "\n",
    "    ax.set_ylim(ymin=0)\n",
    "    ax.set_ylim(ymax=1)\n",
    "    ax.set_xlabel('Machine Learning Algorithm')\n",
    "    ax.set_ylabel('Accuracy')\n",
    "    ax.set_title('Algorithm Performance Predicting Feature: ' + data.default_target_attribute)\n",
    "    plt.axhline(y=maxBaseline, color='r', linestyle='--', label=maxBaseline)\n",
    "    plt.gca().get_yticklabels()[6].set_color('red')\n",
    "    for bar in barlist:\n",
    "        if bar.get_height() > maxBaseline:\n",
    "            bar.set_facecolor('g')\n",
    "    fig.autofmt_xdate()\n",
    "    fig.tight_layout()\n",
    "    plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build Random Forest model from the dataset and compute important features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_forest(data):    \n",
    "    X, y, features = data.get_data(target=data.default_target_attribute, return_attribute_names=True); \n",
    "    forest = Pipeline([('Imputer', preprocessing.Imputer(missing_values='NaN', strategy='mean', axis=0)),\n",
    "                       ('classifiers', RandomForestClassifier(n_estimators=100, random_state=0))])\n",
    "    forest.fit(X,y)\n",
    "    \n",
    "    importances = forest.steps[1][1].feature_importances_\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    return data.name, features, importances, indices "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot Top-20 important features for the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importances(features, importances, indices):\n",
    "    a = 0.8\n",
    "    f_sub = []\n",
    "    max_features = 20\n",
    "\n",
    "    for f in range(min(len(features), max_features)): \n",
    "            f_sub.append(f)\n",
    "\n",
    "    # Create a figure of given size\n",
    "    fig = plt.figure(figsize=(6, 4))\n",
    "    ax = fig.add_subplot(111)\n",
    "    # Set title\n",
    "    ttl = dataset_name\n",
    "\n",
    "    df = pd.DataFrame(importances[indices[f_sub]][::-1])\n",
    "    df.plot(kind='barh', ax=ax, alpha=a, legend=False, edgecolor='w', \n",
    "            title=ttl, color = [plt.cm.viridis(np.arange(len(df))*10)])\n",
    "\n",
    "    # Remove grid lines and plot frame\n",
    "    ax.grid(False)\n",
    "    ax.set_frame_on(False)\n",
    "\n",
    "    # Customize title\n",
    "    ax.set_title(ax.get_title(), fontsize=14, alpha=a, ha='left', x=0, y=1.0)\n",
    "    plt.subplots_adjust(top=0.9)\n",
    "\n",
    "    # Customize x tick lables\n",
    "    ax.xaxis.set_major_formatter(FormatStrFormatter('%.3f'))\n",
    "    ax.locator_params(axis='x', tight=True, nbins=5)\n",
    "\n",
    "    # Customize y tick labels\n",
    "    yticks = np.array(features)[indices[f_sub]][::-1]\n",
    "    ax.set_yticklabels(yticks, fontsize=8, alpha=a)\n",
    "    ax.yaxis.set_tick_params(pad=2)\n",
    "    ax.yaxis.set_ticks_position('none')  \n",
    "    ax.set_ylim(ax.get_ylim()[0]-0.5, ax.get_ylim()[1]+0.5) \n",
    "\n",
    "    # Set x axis text\n",
    "    xlab = 'Feature importance'\n",
    "    ax.set_xlabel(xlab, fontsize=10, alpha=a)\n",
    "    ax.xaxis.set_label_coords(0.5, -0.1)\n",
    "\n",
    "    # Set y axis text\n",
    "    ylab = 'Feature'\n",
    "    ax.set_ylabel(ylab, fontsize=10, alpha=a)\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose desired dataset and generate the most important plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 152"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1aad1b9a390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = oml.datasets.get_dataset(dataset)\n",
    "dataset_name, features, importances, indices = build_forest(data)\n",
    "plot_feature_importances(features, importances, indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot of the classification baseline acuracy of the various baseline strategies using scikit-learn DummyClassifier.\n",
    "\n",
    "The target feature is: **class**\n",
    "\n",
    "The following baseline strategies are used: stratified, most_frequent, prior, uniform.\n",
    "\n",
    "The strategies work as follow according to the sciki-learn API:\n",
    "\n",
    "- **stratified**: Generates predictions by respecting the training set’s class distribution.\n",
    "\n",
    "- **most_frequent**: Always predicts the most frequent label in the training set. Also known as ZeroR.\n",
    "\n",
    "- **prior**: Always predicts the class that maximizes the class prior. \n",
    "\n",
    "- **uniform**: Generates predictions uniformly at random.\n",
    "\n",
    "The horizontal red dotted line denotes the baseline value for this dataset which is equal to the best performing baseline strategy.\n",
    "\n",
    "[More information.](http://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyClassifier.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1aa800685f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "maxBaseline = plot_baseline(baseline(data))\n",
    "strats = {} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Runs the decision tree classification algorithm with default hyperparameters using scikit-learn DecisionTreeClassifier.\n",
    "\n",
    "[Explanation of how a decision tree works.](http://scikit-learn.org/stable/modules/tree.html)\n",
    "\n",
    "The following hyperparameters have been added and can directly be changed in this notebook for further experimentation.\n",
    "Their descriptions are according to the sciki-learn API:\n",
    "\n",
    "- **criterion**:  string, optional (default=”gini”)\n",
    "\n",
    "The function to measure the quality of a split. Supported criteria are “gini” for the Gini impurity and “entropy” for the information gain.\n",
    "\n",
    "- **max_depth**: int or None, optional (default=None)\n",
    "\n",
    "The maximum depth of the tree. If None, then nodes are expanded until all leaves are pure or until all leaves contain less than min_samples_split samples.\n",
    "\n",
    "- **min_samples_leaf**:  int, float, optional (default=1)\n",
    "\n",
    "The minimum number of samples required to be at a leaf node:\n",
    "\n",
    "- If int, then consider min_samples_leaf as the minimum number.\n",
    "- If float, then min_samples_leaf is a percentage and ceil(min_samples_leaf * n_samples) are the minimum number of samples for each node.\n",
    "\n",
    "\n",
    "- **max_features**: int, float, string or None, optional (default=None)\n",
    "\n",
    "The number of features to consider when looking for the best split:\n",
    "\n",
    "- If int, then consider max_features features at each split.\n",
    "- If float, then max_features is a percentage and int(max_features * n_features) features are considered at each split.\n",
    "- If “auto”, then max_features=sqrt(n_features).\n",
    "- If “sqrt”, then max_features=sqrt(n_features).\n",
    "- If “log2”, then max_features=log2(n_features).\n",
    "- If None, then max_features=n_features.\n",
    "\n",
    "Note: the search for a split does not stop until at least one valid partition of the node samples is found, even if it requires to effectively inspect more than max_features features. \n",
    "\n",
    "- **max_leaf_nodes**: int or None, optional (default=None)\n",
    "\n",
    "Grow a tree with max_leaf_nodes in best-first fashion. Best nodes are defined as relative reduction in impurity. If None then unlimited number of leaf nodes.\n",
    "\n",
    "[More information and additional hyperparameters.](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of folds would increase the complexity over the given threshold, number of folds has been set to: 5\n"
     ]
    }
   ],
   "source": [
    "#Runs the decision tree classifier algorithm on the dataset\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import KFold\n",
    "#Running default values, it is recommended to experiment with the values of the parameters below. Try min_samples_leaf=5\n",
    "clf = tree.DecisionTreeClassifier(criterion=\"gini\", max_depth=None, min_samples_leaf=1, max_features=None, max_leaf_nodes=None)\n",
    "X, y, features = data.get_data(target=data.default_target_attribute, return_attribute_names=True); \n",
    "folds = 10\n",
    "acc = 0\n",
    "\n",
    "X = np.nan_to_num(X) \n",
    "y = np.nan_to_num(y)\n",
    "\n",
    "p = len(features)\n",
    "n = len(X)\n",
    "#computational complexity O(n^2 * p)\n",
    "complexity = n**2 * p\n",
    "\n",
    "if complexity <= comp or comp == -1:\n",
    "    for x in range(1,folds+1):\n",
    "        if (n**2 * p * x) > comp and comp != -1:\n",
    "            folds = x-1\n",
    "            print(\"Number of folds would increase the complexity over the given threshold, number of folds has been set to: \" + str(folds))\n",
    "            break\n",
    "    if folds > len(y):\n",
    "        print(\"Number of folds are larger than number of samples, number of folds has been set to: \" + str(len(y)))\n",
    "        folds = len(y)\n",
    "    kf = KFold(n_splits=folds) \n",
    "    for train_index, test_index in kf.split(X,y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        clf.fit(X_train, y_train)\n",
    "        acc += clf.score(X_test, y_test)\n",
    "    strats['decision tree'] = acc / folds\n",
    "else: \n",
    "    print(\"computation complexity too high, please run manually if desired.\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Runs the multinomial naive bayes algorithm with default hyperparameters using scikit-learn MultinomialNB.\n",
    "\n",
    "[Explanation of how naive bayes works.](http://scikit-learn.org/stable/modules/naive_bayes.html)\n",
    "\n",
    "The following hyperparameter has been added and can directly be changed in this notebook for further experimentation.\n",
    "The description according to the sciki-learn API is:\n",
    "\n",
    "- **alpha** : float, optional (default=1.0)\n",
    "\n",
    "Additive (Laplace/Lidstone) smoothing parameter (0 for no smoothing).\n",
    "\n",
    "[More information and additional hyperparameters.](http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Runs the multinomial naive bayes algorithm on the dataset\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import KFold\n",
    "#Running default values, it is recommended to experiment with the values of the parameters below.\n",
    "clf = MultinomialNB(alpha=1.0)\n",
    "X, y, features = data.get_data(target=data.default_target_attribute, return_attribute_names=True); \n",
    "folds = 10\n",
    "acc = 0\n",
    "\n",
    "X = np.nan_to_num(X) \n",
    "y = np.nan_to_num(y)\n",
    "\n",
    "p = len(features)\n",
    "n = len(X)\n",
    "#computational complexity O(n * p)\n",
    "complexity = n * p\n",
    "\n",
    "if complexity <= comp or comp == -1:\n",
    "    for x in range(1,folds+1):\n",
    "        if ((n * p) * x ) > comp and comp != -1:\n",
    "            folds = x-1\n",
    "            print(\"Number of folds would increase the complexity over the given threshold, number of folds has been set to: \" + str(folds))\n",
    "            break\n",
    "    if folds > len(y):\n",
    "        print(\"Number of folds are larger than number of samples, number of folds has been set to: \" + str(len(y)))\n",
    "        folds = len(y)\n",
    "    kf = KFold(n_splits=folds) \n",
    "    for train_index, test_index in kf.split(X,y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        clf.fit(X_train, y_train)\n",
    "        acc += clf.score(X_test, y_test)\n",
    "    strats['naive bayes'] = acc / folds\n",
    "else: \n",
    "    print(\"computation complexity too high, please run manually if desired.\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Runs the random forest classification algorithm with default hyperparameters using scikit-learn RandomForestClassifier.\n",
    "\n",
    "[Explanation of how a random forest works.](http://scikit-learn.org/stable/modules/ensemble.html#forests-of-randomized-trees)\n",
    "\n",
    "The following hyperparameters have been added and can directly be changed in this notebook for further experimentation.\n",
    "Their descriptions are according to the sciki-learn API:\n",
    "\n",
    "- **n_estimators** : integer, optional (default=10)\n",
    "\n",
    "The number of trees in the forest.\n",
    "\n",
    "- **criterion**:  string, optional (default=”gini”)\n",
    "\n",
    "The function to measure the quality of a split. Supported criteria are “gini” for the Gini impurity and “entropy” for the information gain. Note: this parameter is tree-specific.\n",
    "\n",
    "- **max_depth**: integer or None, optional (default=None)\n",
    "\n",
    "The maximum depth of the tree. If None, then nodes are expanded until all leaves are pure or until all leaves contain less than min_samples_split samples.\n",
    "\n",
    "- **min_samples_leaf**:  int, float, optional (default=1)\n",
    "\n",
    "The minimum number of samples required to be at a leaf node:\n",
    "\n",
    "- If int, then consider min_samples_leaf as the minimum number.\n",
    "- If float, then min_samples_leaf is a percentage and ceil(min_samples_leaf * n_samples) are the minimum number of samples for each node.\n",
    "\n",
    "\n",
    "- **max_features**: int, float, string or None, optional (default=”auto”)\n",
    "\n",
    "The number of features to consider when looking for the best split:\n",
    "\n",
    "- If int, then consider max_features features at each split.\n",
    "- If float, then max_features is a percentage and int(max_features * n_features) features are considered at each split.\n",
    "- If “auto”, then max_features=sqrt(n_features).\n",
    "- If “sqrt”, then max_features=sqrt(n_features) (same as “auto”).\n",
    "- If “log2”, then max_features=log2(n_features).\n",
    "- If None, then max_features=n_features.\n",
    "\n",
    "Note: the search for a split does not stop until at least one valid partition of the node samples is found, even if it requires to effectively inspect more than max_features features.\n",
    "\n",
    "- **max_leaf_nodes**: int or None, optional (default=None)\n",
    "\n",
    "Grow trees with max_leaf_nodes in best-first fashion. Best nodes are defined as relative reduction in impurity. If None then unlimited number of leaf nodes.\n",
    "\n",
    "[More information and additional hyperparameters.](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computation complexity too high, please run manually if desired.\n"
     ]
    }
   ],
   "source": [
    "#Runs the random forest classifier algorithm on the dataset\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "#Running default values, it is recommended to experiment with the values of the parameters below. Try changing n_trees/n_estimators and max_depth.\n",
    "n_trees = 10 #Sets n_estimators such that the complexity value is calculated correctly.\n",
    "clf = RandomForestClassifier(n_estimators=n_trees, criterion=\"gini\", max_depth=None, min_samples_leaf=1, max_features=None, max_leaf_nodes=None)\n",
    "X, y, features = data.get_data(target=data.default_target_attribute, return_attribute_names=True); \n",
    "folds = 10\n",
    "acc = 0\n",
    "\n",
    "X = np.nan_to_num(X) \n",
    "y = np.nan_to_num(y)\n",
    "\n",
    "p = len(features)\n",
    "n = len(X)\n",
    "#computational complexity O(n^2 * p * n_trees)\n",
    "complexity = n**2 * p * n_trees\n",
    "\n",
    "if complexity <= comp or comp == -1:\n",
    "    for x in range(1,folds+1):\n",
    "        if (n**2 * p * n_trees) > comp and comp != -1:\n",
    "            folds = x-1\n",
    "            print(\"Number of folds would increase the complexity over the given threshold, number of folds has been set to: \" + str(folds))\n",
    "            break\n",
    "    if folds > len(y):\n",
    "        print(\"Number of folds are larger than number of samples, number of folds has been set to: \" + str(len(y)))\n",
    "        folds = len(y)\n",
    "    kf = KFold(n_splits=folds) \n",
    "    for train_index, test_index in kf.split(X,y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        clf.fit(X_train, y_train)\n",
    "        acc += clf.score(X_test, y_test)\n",
    "    strats['random forest'] = acc / folds\n",
    "else: \n",
    "    print(\"computation complexity too high, please run manually if desired.\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Runs the classification support vector machine algorithm with default hyperparameters using scikit-learn SVC.\n",
    "\n",
    "[Explanation of how a support vector machine works.](http://scikit-learn.org/stable/modules/svm.html)\n",
    "\n",
    "The following hyperparameters have been added and can directly be changed in this notebook for further experimentation.\n",
    "Their descriptions are according to the sciki-learn API:\n",
    "\n",
    "- **C** : float, optional (default=1.0)\n",
    "\n",
    "Penalty parameter C of the error term.\n",
    "\n",
    "- **kernel**:  string, optional (default=’rbf’)\n",
    "\n",
    "Specifies the kernel type to be used in the algorithm. It must be one of ‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’ or a callable. If none is given, ‘rbf’ will be used. If a callable is given it is used to pre-compute the kernel matrix from data matrices; that matrix should be an array of shape (n_samples, n_samples).\n",
    "\n",
    "- **gamma**: float, optional (default=’auto’)\n",
    "\n",
    "Kernel coefficient for ‘rbf’, ‘poly’ and ‘sigmoid’. If gamma is ‘auto’ then 1/n_features will be used instead.\n",
    "\n",
    "[More information and additional hyperparameters.](http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computation complexity too high, please run manually if desired.\n"
     ]
    }
   ],
   "source": [
    "#Runs the classification support vector machine algorithm on the dataset\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import KFold\n",
    "#Running default values, it is recommended to experiment with the values of the parameters below.\n",
    "clf = svm.SVC(C =1.0, kernel=\"rbf\", gamma=\"auto\")\n",
    "X, y, features = data.get_data(target=data.default_target_attribute, return_attribute_names=True); \n",
    "folds = 10\n",
    "acc = 0\n",
    "\n",
    "X = np.nan_to_num(X) \n",
    "y = np.nan_to_num(y)\n",
    "\n",
    "p = len(features)\n",
    "n = len(X)\n",
    "#computational complexity O(n^2 * p + n^3)\n",
    "complexity = n**2 * p + n**3\n",
    "\n",
    "if complexity <= comp or comp == -1:\n",
    "    for x in range(1,folds+1):\n",
    "        if ((n**2 * p + n**3) * x) > comp and comp != -1:\n",
    "            folds = x-1\n",
    "            print(\"Number of folds would increase the complexity over the given threshold, number of folds has been set to: \" + str(folds))\n",
    "            break\n",
    "    if folds > len(y):\n",
    "        print(\"Number of folds are larger than number of samples, number of folds has been set to: \" + str(len(y)))\n",
    "        folds = len(y)\n",
    "    kf = KFold(n_splits=folds) \n",
    "    for train_index, test_index in kf.split(X,y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        clf.fit(X_train, y_train)\n",
    "        acc += clf.score(X_test, y_test)\n",
    "    strats['support vector machine'] = acc / folds\n",
    "else: \n",
    "    print(\"computation complexity too high, please run manually if desired.\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Runs the classification k-nearest neighbours algorithm with default hyperparameters using scikit-learn KNeighborsClassifier.\n",
    "\n",
    "[Explanation of how k-nearest neighbours works.](http://scikit-learn.org/stable/modules/neighbors.html)\n",
    "\n",
    "The following hyperparameters have been added and can directly be changed in this notebook for further experimentation.\n",
    "Their descriptions are according to the sciki-learn API:\n",
    "\n",
    "- **n_neighbors** : int, optional (default = 5)\n",
    "\n",
    "Number of neighbors to use by default for kneighbors queries.\n",
    "\n",
    "- **weights** : str or callable, optional (default = ‘uniform’)\n",
    "\n",
    "weight function used in prediction. Possible values:\n",
    "\n",
    "- ‘uniform’ : uniform weights. All points in each neighborhood are weighted equally.\n",
    "- ‘distance’ : weight points by the inverse of their distance. in this case, closer neighbors of a query point will have a greater influence than neighbors which are further away.\n",
    "- [callable] : a user-defined function which accepts an array of distances, and returns an array of the same shape containing the weights.\n",
    "\n",
    "- algorithm : {‘auto’, ‘ball_tree’, ‘kd_tree’, ‘brute’}, optional\n",
    "\n",
    "Algorithm used to compute the nearest neighbors:\n",
    "\n",
    "- ‘ball_tree’ will use BallTree\n",
    "- ‘kd_tree’ will use KDTree\n",
    "- ‘brute’ will use a brute-force search.\n",
    "- ‘auto’ will attempt to decide the most appropriate algorithm based on the values passed to fit method.\n",
    "\n",
    "Note: fitting on sparse input will override the setting of this parameter, using brute force.\n",
    "\n",
    "[More information and additional hyperparameters.](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Runs the classification k-nearest neighbours algorithm on the dataset\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "#Running default values, it is recommended to experiment with the values of the parameters below.\n",
    "clf = KNeighborsClassifier(n_neighbors = 5, weights = \"uniform\", algorithm = \"auto\")\n",
    "X, y, features = data.get_data(target=data.default_target_attribute, return_attribute_names=True); \n",
    "folds = 10\n",
    "acc = 0\n",
    "\n",
    "X = np.nan_to_num(X) \n",
    "y = np.nan_to_num(y)\n",
    "\n",
    "p = len(features)\n",
    "n = len(X)\n",
    "#computational complexity O(n * p)\n",
    "complexity = n * p \n",
    "\n",
    "if complexity <= comp or comp == -1:\n",
    "    for x in range(1,folds+1):\n",
    "        if (n * p * x) > comp and comp != -1:\n",
    "            folds = x-1\n",
    "            print(\"Number of folds would increase the complexity over the given threshold, number of folds has been set to: \" + str(folds))\n",
    "            break\n",
    "    if folds > len(y):\n",
    "        print(\"Number of folds are larger than number of samples, number of folds has been set to: \" + str(len(y)))\n",
    "        folds = len(y)\n",
    "    kf = KFold(n_splits=folds) \n",
    "    for train_index, test_index in kf.split(X,y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        clf.fit(X_train, y_train)\n",
    "        acc += clf.score(X_test, y_test)\n",
    "    strats['k-nearest neighbours'] = acc / folds\n",
    "else: \n",
    "    print(\"computation complexity too high, please run manually if desired.\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the accuracy of various machine learning algorithms against the baseline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1aa8017b860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_alg(strats, maxBaseline) "
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}
